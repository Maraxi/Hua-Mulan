{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### This notebook was run in a googlecolab environment using GPU\n",
    "###\n",
    "\n",
    "!pip install sentencepiece\n",
    "!pip install transformers\n",
    "\n",
    "from itertools import chain\n",
    "import torch \n",
    "from transformers import AutoConfig, AutoModelWithLMHead, AutoTokenizer\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "#import torch_xla\n",
    "#import torch_xla.core.xla_model as xm\n",
    "dev = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM_MODEL_TO_USE = \"gpt2\"\n",
    "device = torch.device( dev)\n",
    "tokenizer = AutoTokenizer.from_pretrained(LM_MODEL_TO_USE)\n",
    "lm = AutoModelWithLMHead.from_pretrained(LM_MODEL_TO_USE)\n",
    "lm.eval()\n",
    "\n",
    "lm.to(device)\n",
    "for param in lm.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = pd.read_csv(\"args.tsv\", sep =\"\\t\")\n",
    "len(args[\"conclusion\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "for inp in args[\"conclusion\"].unique():\n",
    "    x = torch.tensor(tokenizer.encode(inp)).unsqueeze(0) \n",
    "    start = torch.tensor(tokenizer.encode(\"- What do you think about: \" )).unsqueeze(0)\n",
    "    end = torch.tensor(tokenizer.encode(\". Do you agree? \\n -The answer is no, because \")).unsqueeze(0)\n",
    "    if x.size()[1]>78:\n",
    "        input_ids = input_ids[:,:77]\n",
    "        print(\"trunc\")\n",
    "    input_ids = torch.cat((start,x,end),1).to(device) \n",
    "    inputs.append(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y = []\n",
    "for x in inputs:\n",
    "    pred = lm.generate(input_ids=x, stepsize=0.03,num_samples=2, temperature=1.7, max_length=250, top_k=10, grad_length=1000, horizon_length=9,\n",
    "                                                                                          gm_scale=0.9, kl_scale=0.7, repetition_penalty=2.0, gamma=1.5)\n",
    "    y.append(tokenizer.decode(pred[0]))\n",
    "pd.DataFrame({\"conclusion\": list(args[\"conclusion\"].unique()), \"negative\": y}).to_csv(\"gpt2_negative.csv\", \"\\t\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
